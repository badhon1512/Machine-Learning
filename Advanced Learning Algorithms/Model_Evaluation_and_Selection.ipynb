{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44097cf-cfb1-458e-8037-2cd6c727f51c",
   "metadata": {},
   "source": [
    "Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50e72223-9843-4c05-ac56-df058472f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d6c39-65fa-4a10-ae87-be7f485fd3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f275f04c-5715-418f-beed-b320f4e4541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = datasets.make_regression(n_samples=500, n_features=1, noise=0.1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f364d187-36a4-46f7-b46b-689848343c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset for train, validation and test \n",
    "X_train, X_,y_train,y_ = train_test_split(X,y,test_size=0.4, random_state=1)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_,y_,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ce388-6734-41dc-aeac-cd5ec097bb3e",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2cf1ce86-9eb3-475e-ad31-c8bc8234e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_linear = StandardScaler()\n",
    "X_train_scaled = scale_linear.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9477d139-fa79-4069-a746-20ec255c126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_r = LinearRegression()\n",
    "l_r.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74604e-6225-4d2b-931d-cf7f6baa815b",
   "metadata": {},
   "source": [
    "### Evaluate the Model\r",
    "$$J_{train}(\\vec{w}, b) = \\frac{1}{2m_{train}}\\left[\\sum_{i=1}^{m_{train}}(f_{\\vec{w},b}(\\vec{x}_{train}^{(i)}) - y_{train}^{(i)})^2\\right]$$\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22a2ca9d-2037-42ab-9cf0-9bd4b93ae48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training MSE (using sklearn function): 0.0042610469232920644\n",
      "training MSE (for-loop implementation): 0.004261046923292068\n"
     ]
    }
   ],
   "source": [
    "# Feed the scaled training set and get the predictions\n",
    "yhat = l_r.predict(X_train_scaled)\n",
    "\n",
    "# Use scikit-learn's utility function and divide by 2\n",
    "print(f\"training MSE (using sklearn function): {mean_squared_error(y_train, yhat) / 2}\")\n",
    "\n",
    "# for-loop implementation\n",
    "total_squared_error = 0\n",
    "\n",
    "for i in range(len(yhat)):\n",
    "    total_squared_error += (yhat[i] - y_train[i])**2                                            \n",
    "\n",
    "mse = total_squared_error / (2*len(yhat))\n",
    "\n",
    "print(f\"training MSE (for-loop implementation): {mse.squeeze()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8e7bf82-34d7-4285-80c1-0501e8b455c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean used to scale the CV set: 0.13\n",
      "Standard deviation used to scale the CV set: 1.05\n",
      "Cross validation MSE: 0.004252644390496841\n"
     ]
    }
   ],
   "source": [
    "# Scale the cross validation set using the mean and standard deviation of the training set\n",
    "X_cv_scaled = scale_linear.transform(X_cv)\n",
    "\n",
    "print(f\"Mean used to scale the CV set: {scale_linear.mean_.squeeze():.2f}\")\n",
    "print(f\"Standard deviation used to scale the CV set: {scale_linear.scale_.squeeze():.2f}\")\n",
    "\n",
    "# Feed the scaled cross validation set\n",
    "yhat = l_r.predict(X_cv_scaled)\n",
    "print(f\"Cross validation MSE: {mean_squared_error(y_cv, yhat) / 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468aa2e6-3058-4a7d-ad11-9578fedbedd1",
   "metadata": {},
   "source": [
    "## Adding Polynomial Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c521b6e6-3b8e-4fcd-8a7f-563859453fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.18054717  4.75478595]\n",
      " [ 4.34185038 18.8516647 ]\n",
      " [-0.71742755  0.51470229]\n",
      " [-1.05853579  1.12049803]\n",
      " [-0.24239356  0.05875464]]\n",
      "[[ 1.95309326e+00  2.06644947e+00]\n",
      " [ 4.00911016e+00  1.00836353e+01]\n",
      " [-8.03708737e-01 -3.44973595e-01]\n",
      " [-1.12820014e+00 -4.45061067e-04]\n",
      " [-3.51815677e-01 -6.04280434e-01]]\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "X_train_mapped = poly.fit_transform(X_train)\n",
    "\n",
    "print(X_train_mapped[:5])\n",
    "\n",
    "scale_poly = StandardScaler()\n",
    "\n",
    "X_train_mapped_scaled = scale_poly.fit_transform(X_train_mapped)\n",
    "print(X_train_mapped_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e891b-7cc4-4bda-b215-3bedb4b9363d",
   "metadata": {},
   "source": [
    "### Choose best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02337b8e-cb99-4414-8c4a-7448df322bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004252644390496841, 0.004272857651702618, 0.004275313424276005, 0.004344272626305992]\n"
     ]
    }
   ],
   "source": [
    "train_mses = []\n",
    "cv_mses = []\n",
    "models = []\n",
    "scalers = []\n",
    "\n",
    "for degree in range(1,5):\n",
    "    \n",
    "    # Add polynomial features to the training set\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    X_train_mapped = poly.fit_transform(X_train)\n",
    "    \n",
    "    # Scale the training set\n",
    "    scaler_poly = StandardScaler()\n",
    "    X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)\n",
    "    scalers.append(scaler_poly)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_mapped_scaled, y_train )\n",
    "    models.append(model)\n",
    "    \n",
    "    # Compute the training MSE\n",
    "    yhat = model.predict(X_train_mapped_scaled)\n",
    "    train_mse = mean_squared_error(y_train, yhat) / 2\n",
    "    train_mses.append(train_mse)\n",
    "    \n",
    "    # Add polynomial features and scale the cross validation set\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    X_cv_mapped = poly.fit_transform(X_cv)\n",
    "    X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)\n",
    "    \n",
    "    # Compute the cross validation MSE\n",
    "    yhat = model.predict(X_cv_mapped_scaled)\n",
    "    cv_mse = mean_squared_error(y_cv, yhat) / 2\n",
    "    cv_mses.append(cv_mse)\n",
    "print(cv_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f91115b9-7ffc-4d4e-ac98-1c1fa69d5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest CV MSE is found in the model with degree=1\n"
     ]
    }
   ],
   "source": [
    "degree = np.argmin(cv_mses) + 1\n",
    "print(f\"Lowest CV MSE is found in the model with degree={degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d692515-ed2e-4d04-bc7b-a445f19fcc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.00426\n",
      "Cross Validation MSE: 0.00425\n",
      "Test MSE: 0.00419\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree, include_bias=False)\n",
    "X_test_mapped = poly.fit_transform(X_test)\n",
    "\n",
    "# Scale the test set\n",
    "X_test_mapped_scaled = scalers[degree-1].transform(X_test_mapped)\n",
    "\n",
    "# Compute the test MSE\n",
    "yhat = models[degree-1].predict(X_test_mapped_scaled)\n",
    "test_mse = mean_squared_error(y_test, yhat) / 2\n",
    "\n",
    "print(f\"Training MSE: {train_mses[degree-1]:.5f}\")\n",
    "print(f\"Cross Validation MSE: {cv_mses[degree-1]:.5f}\")\n",
    "print(f\"Test MSE: {test_mse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f962a-0b4d-4d34-875e-7ad0de477b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ac87e2-067d-4407-88c5-b206bb77b396",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0583946-1d10-4e19-9cdf-e02726907a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_linear = StandardScaler()\n",
    "X_train_scaled = scale_linear.fit_transform(X_train)\n",
    "\n",
    "X_cv_scaled = scale_linear.transform(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3fbf0d18-ebc8-4ff8-b1b4-798140297da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 2ms/step - loss: 8511.7686 - mae: 73.3058\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8507.3486 - mae: 73.2856\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8503.1729 - mae: 73.2659\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8498.5371 - mae: 73.2449\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8494.1211 - mae: 73.2250\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 3ms/step - loss: 8522.4346 - mae: 73.3296\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8514.7070 - mae: 73.2882\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8507.0449 - mae: 73.2468\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8498.7871 - mae: 73.2035\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8490.6689 - mae: 73.1600\n",
      "10/10 [==============================] - 0s 997us/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 4ms/step - loss: 8539.7930 - mae: 73.4155\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8537.6133 - mae: 73.4056\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8535.6064 - mae: 73.3976\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8533.7979 - mae: 73.3907\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8531.9512 - mae: 73.3826\n",
      "10/10 [==============================] - 0s 926us/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 3ms/step - loss: 8535.0088 - mae: 73.3810\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8523.9648 - mae: 73.3338\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8512.7197 - mae: 73.2860\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8501.3496 - mae: 73.2375\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8490.3516 - mae: 73.1912\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 4ms/step - loss: 8542.3398 - mae: 73.4280\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8533.2354 - mae: 73.3870\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8526.8330 - mae: 73.3565\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8520.4893 - mae: 73.3265\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8514.3096 - mae: 73.2988\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "train_mses = []\n",
    "cv_mses = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(i+6, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dense(i+3, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='linear')  #linear for regression\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    model.fit(X_train_scaled,y_train, epochs=5)\n",
    "    \n",
    "    y_hat = model.predict(X_train_scaled)\n",
    "    mse = mean_squared_error(y_train,y_hat)/2\n",
    "    train_mses.append(mse)\n",
    "\n",
    "    y_hat = model.predict(X_cv_scaled)\n",
    "    mse = mean_squared_error(y_cv,y_hat)/2\n",
    "    cv_mses.append(mse)\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a29112-07bb-443c-a31e-2b352c004879",
   "metadata": {},
   "source": [
    "### Fidning best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de41afb8-f29f-431f-93cf-283510a54f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 7)                 14        \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 4)                 32        \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Best model None\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - mae: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_i = np.argmin(cv_mses)\n",
    "print(f\"Best model {models[m_i].summary()}\")\n",
    "X_test_scaled = scale_linear.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "50a82335-8f2a-4150-86f0-9d4da4db4d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step - loss: 11697.4688 - mae: 80.5075\n",
      "accuracy 80.51 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy {models[m_i].evaluate(X_test_scaled,y_test)[1]:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c07d2a-d57b-499a-93ba-cab01a052a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
